{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(num_data):\n",
    "    #generate number of each label\n",
    "    num_1 = sum(np.random.randint(2, size = num_data))\n",
    "    num_2 = num_data - num_1\n",
    "\n",
    "    #generate data based on number of each label\n",
    "    mean_1 = [2, 3]\n",
    "    cov_1 = [[0.6, 0], [0, 0.6]]\n",
    "    mean_2 = [0, 4]\n",
    "    cov_2 = [[0.4, 0], [0, 0.4]]\n",
    "\n",
    "    fake_point_1 = np.random.multivariate_normal(mean_1, cov_1, size = num_1)\n",
    "    fake_point_2 = np.random.multivariate_normal(mean_2, cov_2, size = num_2)\n",
    "    fake_points = np.concatenate([fake_point_1, fake_point_2], axis = 0)\n",
    "    fake_points = np.concatenate([np.ones_like(fake_points[:, 0]).reshape(-1, 1), fake_points], axis = 1)\n",
    "\n",
    "    label_1 = np.ones(num_1)\n",
    "    label_2 = np.ones(num_2) * (-1)\n",
    "    labels = np.concatenate([label_1, label_2], axis = 0)\n",
    "    return fake_points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, label_train = generate_fake_data(200)\n",
    "data_test, label_test = generate_fake_data(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(200,)\n",
      "(5000, 3)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(label_train.shape)\n",
    "print(data_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_linear_regression(data, label):\n",
    "    w = np.linalg.lstsq(data, label, rcond=None)[0].reshape(-1, 1)\n",
    "    y_hat = np.dot(data, w).reshape(-1)\n",
    "    return w, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in^sqr is 0.2865835469477231\n"
     ]
    }
   ],
   "source": [
    "num_experiment = 100\n",
    "ttl_loss = 0\n",
    "for i in range(num_experiment):\n",
    "    np.random.seed(i)\n",
    "    data_train, label_train = generate_fake_data(200)\n",
    "    data_test, label_test = generate_fake_data(5000)\n",
    "    _, y_hat = solve_linear_regression(data_train, label_train)\n",
    "    avg_squared_error = np.mean((y_hat - label_train) ** 2)\n",
    "    ttl_loss += avg_squared_error\n",
    "print(f\"E_in^sqr is {ttl_loss / num_experiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probelm 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error difference is 0.013424\n"
     ]
    }
   ],
   "source": [
    "num_experiment = 100\n",
    "ttl_loss = 0\n",
    "ttl_train = 0\n",
    "ttl_test = 0\n",
    "for i in range(num_experiment):\n",
    "    np.random.seed(i)\n",
    "    data_train, label_train = generate_fake_data(200)\n",
    "    data_test, label_test = generate_fake_data(5000)\n",
    "\n",
    "    #training error\n",
    "    w, y_hat_train = solve_linear_regression(data_train, label_train)\n",
    "    y_hat_train = np.sign(y_hat_train)\n",
    "    num_correct_train = sum(y_hat_train == label_train)\n",
    "    num_wrong_train = len(data_train) - num_correct_train\n",
    "    error_train = num_wrong_train / len(data_train)\n",
    "    ttl_train += error_train\n",
    "\n",
    "    #testing error\n",
    "    y_hat_test = np.dot(data_test, w).reshape(-1)\n",
    "    y_hat_test = np.sign(y_hat_test)\n",
    "    num_correct_test = sum(y_hat_test == label_test)\n",
    "    num_wrong_test = len(data_test) - num_correct_test\n",
    "    error_test = num_wrong_test / len(data_test)\n",
    "    ttl_test += error_test\n",
    "\n",
    "    #compute error difference\n",
    "    ttl_loss += np.abs(error_train - error_test)\n",
    "\n",
    "print(f\"Average error difference is {ttl_loss / num_experiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def solve_logistic_regression(data_train, label_train):\n",
    "    num_iter = 500\n",
    "    eta = 0.1\n",
    "    w = np.zeros_like(data_train[0, :])\n",
    "    for i in range(num_iter):\n",
    "        grad = np.zeros_like(w)\n",
    "        for j in range(len(data_train)):\n",
    "            logit = sigmoid(-1 * label_train[j] * np.dot(w, data_train[j]))\n",
    "            grad += logit * (-label_train[j]) * data_train[j]\n",
    "        grad = grad / len(data_train)\n",
    "        w = w - eta * grad\n",
    "    return w, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error difference in model A is 0.058165999999999975\n",
      "Average error difference in model B is 0.05943399999999998\n"
     ]
    }
   ],
   "source": [
    "num_experiment = 100\n",
    "ttl_loss = 0\n",
    "ttl_A = 0\n",
    "ttl_B = 0\n",
    "for i in range(num_experiment):\n",
    "    np.random.seed(i)\n",
    "    data_train, label_train = generate_fake_data(200)\n",
    "    data_test, label_test = generate_fake_data(5000)\n",
    "\n",
    "    #model - A\n",
    "    w_lin, y_hat_train = solve_linear_regression(data_train, label_train)\n",
    "    y_hat_train = np.sign(y_hat_train)\n",
    "\n",
    "    #testing error\n",
    "    y_hat_test = np.dot(data_test, w_lin).reshape(-1)\n",
    "    y_hat_test = np.sign(y_hat_test)\n",
    "    num_correct_test = sum(y_hat_test == label_test)\n",
    "    num_wrong_test = len(data_test) - num_correct_test\n",
    "    error_test_A = num_wrong_test / len(data_test)\n",
    "    ttl_A += error_test_A\n",
    "\n",
    "    #model - B \n",
    "    w, y_hat_train = solve_logistic_regression(data_train, label_train)\n",
    "    y_hat_test = np.dot(data_test, w).reshape(-1)\n",
    "    y_hat_test = np.sign(y_hat_test)\n",
    "    \n",
    "    num_correct_test = sum(y_hat_test == label_test)\n",
    "    num_wrong_test = len(data_test) - num_correct_test\n",
    "    error_test_B = num_wrong_test / len(data_test)\n",
    "    ttl_B += error_test_B\n",
    "    #print(error_test_A, error_test_B)\n",
    "print(f\"Average error difference in model A is {ttl_A / num_experiment}\")\n",
    "print(f\"Average error difference in model B is {ttl_B / num_experiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outlier(num_data):\n",
    "    #generate data based on number of each label\n",
    "    mean = [6, 0]\n",
    "    cov = [[0.3, 0], [0, 0.1]]\n",
    "    fake_point = np.random.multivariate_normal(mean, cov, size = num_data)\n",
    "    fake_point = np.concatenate([np.ones_like(fake_point[:, 0]).reshape(-1, 1), fake_point], axis = 1)\n",
    "\n",
    "    label = np.ones(num_data)\n",
    "    return fake_point, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error difference in model A is 0.09350199999999996\n",
      "Average error difference in model B is 0.059572\n"
     ]
    }
   ],
   "source": [
    "num_experiment = 100\n",
    "ttl_loss = 0\n",
    "ttl_A = 0\n",
    "ttl_B = 0\n",
    "\n",
    "for i in range(num_experiment):\n",
    "    np.random.seed(i)\n",
    "\n",
    "    data_train, label_train = generate_fake_data(200)\n",
    "    data_train_out, label_train_out = generate_outlier(20)\n",
    "    data_train = np.concatenate([data_train, data_train_out], axis = 0)\n",
    "    label_train = np.concatenate([label_train, label_train_out], axis = 0)\n",
    "\n",
    "    data_test, label_test = generate_fake_data(5000)\n",
    "\n",
    "    #model - A\n",
    "    w_lin, y_hat_train = solve_linear_regression(data_train, label_train)\n",
    "    y_hat_train = np.sign(y_hat_train)\n",
    "\n",
    "    #testing error\n",
    "    y_hat_test = np.dot(data_test, w_lin).reshape(-1)\n",
    "    y_hat_test = np.sign(y_hat_test)\n",
    "    num_correct_test = sum(y_hat_test == label_test)\n",
    "    num_wrong_test = len(data_test) - num_correct_test\n",
    "    error_test_A = num_wrong_test / len(data_test)\n",
    "    ttl_A += error_test_A\n",
    "\n",
    "    #model - B \n",
    "    w, y_hat_train = solve_logistic_regression(data_train, label_train)\n",
    "    y_hat_test = np.dot(data_test, w).reshape(-1)\n",
    "    y_hat_test = np.sign(y_hat_test)\n",
    "    \n",
    "    num_correct_test = sum(y_hat_test == label_test)\n",
    "    num_wrong_test = len(data_test) - num_correct_test\n",
    "    error_test_B = num_wrong_test / len(data_test)\n",
    "    ttl_B += error_test_B\n",
    "    #print(error_test_A, error_test_B)\n",
    "print(f\"Average error difference in model A is {ttl_A / num_experiment}\")\n",
    "print(f\"Average error difference in model B is {ttl_B / num_experiment}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50bc8ce3d1f752641134e147d4e62e8ba66bb5292f815a5a3dd7adbd21f01ef0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('test': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
